{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook to load and prepare the brain datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from glob import glob\n",
    "from itertools import combinations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Insert the path containing the main folder where the correlation matrices, high-order interactions (HOI) metrics and clinical features of the volunteers are stored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_dir = 'path/to/correlation/files/'\n",
    "hoi_dir = \"path/to/hoi/files/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the brain datasets and build a dataframe with volunteers information, such as, Subject ID, fMRI resting-state runs number (REST), Gender, Age, ect..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search for all files in the directory including subdirectories\n",
    "hoi_dir += '**/*.csv'\n",
    "corr_dir += '**/*_Atlas_MSMAll_hp2000_clean_Schaefer2018_100Parcels_7Networks_Tian_Subcortex_S1_3T_connmatrix.txt'\n",
    "\n",
    "# Get all files of the individual's correlation matrices in the directory and store in a dataframe with the corresponding subject, REST and file path\n",
    "corr_files = glob(corr_dir, recursive=True)\n",
    "idx = corr_files[0].index(\"_REST\")\n",
    "files_id = [int(f[idx-12:idx-6]) for f in corr_files]\n",
    "files_rest = [int(f[idx + 5]) for f in corr_files]\n",
    "df_corr = pd.DataFrame({'Subject':files_id,'REST':files_rest,'corr_dir':corr_files})\n",
    "\n",
    "# Get all files of HOIs in the directory and store in a dataframe with the corresponding subject, REST and file path\n",
    "hoi_files = glob(hoi_dir, recursive=True)\n",
    "idx = hoi_files[0].index(\"_REST\")\n",
    "files_id = [int(f[idx-11:idx-5]) for f in hoi_files]\n",
    "files_rest = [int(f[idx + 5]) for f in hoi_files]\n",
    "df_hoi = pd.DataFrame({'Subject':files_id,'REST':files_rest,'hoi_dir':hoi_files})\n",
    "\n",
    "# Merge the correlation and HOI dataframes on the subject ID and REST columns\n",
    "df_corr_hoi = pd.merge(df_corr, df_hoi,on=['Subject','REST'], how='right')\n",
    "\n",
    "# Read the table containing the subject ID and gender information of the indivisuals\n",
    "subject_gender_dir = \"./hcp_subject_genders_info.xlsx\"\n",
    "df_gender = pd.read_excel(subject_gender_dir, usecols=['Subject', 'Gender'], engine='openpyxl')\n",
    "\n",
    "# Merge indivisual's information with the correlation and HOI dataframes.\n",
    "# This dataframe contains the selected individuals for the experiments of this study\n",
    "df_gender_corr_hoi = pd.merge(df_gender, df_corr_hoi, how=\"inner\", on=[\"Subject\"])\n",
    "df_gender_corr_hoi.dropna(inplace=True)\n",
    "\n",
    "# Get the list of files of the correlation matrices and HOIs\n",
    "files_corr = df_gender_corr_hoi.loc[:, \"corr_dir\"].tolist()\n",
    "files_hoi = df_gender_corr_hoi.loc[:, \"hoi_dir\"].tolist()\n",
    "\n",
    "n_rois = 116\n",
    "triangles = list(combinations(range(n_rois), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load, compute and store the mean individual correlation matrix, and the z-scored HOI hyperedges using the Interaction Information ($II$) and Total Correlation ($TC$) metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 8/1978 [00:00<01:04, 30.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing averaged correlation matrix...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1978/1978 [00:55<00:00, 35.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done! Averaged correlation matrix saved to ./Schaefer_100Parcels_Atlas/corr_avr_matrix.txt\n",
      "Converting raw hyperedges to z-scored .npy files for further usage...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1978/1978 [19:51<00:00,  1.66it/s]\n",
      "  0%|          | 6/1978 [00:00<00:36, 53.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n",
      "Computing mean individual z-scored hyperedges...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1978/1978 [00:32<00:00, 60.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done! Averaged z-scored hyperedges saved to ./Schaefer_100Parcels_Atlas/hoi_zscored_avr_hyperedges.npy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%run -i \"hgsp_brain_dataset_setup.py\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tda_gsp_hgsp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
